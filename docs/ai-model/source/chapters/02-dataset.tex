

\section{Dataset}

\subsection{Data Source}
The dataset used in this project is the {\textit{IQ-OTH/NCCD - Lung Cancer Dataset}} (The Iraq-Oncol
ogy Teaching Hospital/National Center for Cancer Diseases), publicly available from The Cancer 
Imaging Archive (TCIA). \cite{subhajeet_das_2025}

This dataset was collected in the above-mentioned specialist hospitals over a period of three months 
in fall 2019. It includes CT scans (originally collected in DICOM format) of patients diagnosed 
with lung cancer in different stages, as well as healthy subjects. 

Each scan contains several slices (from 80 to 200), each of them represents an image of the human 
chest with different sides and angles. The cases vary in gender, age, educational attainment, area 
of residence, and living status. Some of them are employees of the Iraqi ministries of Transport and 
Oil, others are farmers and gainers. Most of them come from places in the middle region of Iraq,  
particularly, the provinces of Baghdad, Wasit, Diyala, Salahuddin, and Babylon.

\vspace{1em}
\begin{center} 
    \includegraphics[width=0.7\textwidth]{../assets/02-dataset/ct-scans.png}

    \small\textit{Figure 1. CT scan samples from dataset.}
\end{center}
\vspace{1em}

\subsection{Data Description: Properties, Types and Formats}
The IQ-OTH/NCCD lung cancer dataset consists of 3.609 chest CT scan images collected from 110 
individual patients. Each image is stored in JPEG format with non-uniform resolutions. 

\vspace{1em}
\begin{center} 
    \includegraphics[width=\textwidth]{../assets/02-dataset/image-size-distribution.png}

    \small\textit{Figure 2. Distribution of images size.}
\end{center}
\vspace{1em}

\subsection{Data Annotation: Methods and Categories}
The dataset was manually organized into three distinct folders, each corresponding to a diagnostic 
category used for classification:
\begin{itemize}
    \item \textbf{Normal} – images without visible nodules or abnormalities
    
    \item \textbf{Benign} – images containing nodules classified as non-cancerous
    
    \item \textbf{Malignant} – images containing nodules classified as cancerous
\end{itemize}  
 

The labeling of each image was performed by a team of experienced oncologists and radiologists, 
ensuring a high degree of clinical accuracy and reliability in the annotation process. This 
expert-labeled dataset forms a strong foundation for training a supervised learning model in a 
sensitive medical context.

This folder-based organization enabled the model to correctly associate each image with its 
corresponding class label during training and evaluation. The distribution of these labeled samples 
is presented in \hyperlink{figura3}Figure 3.

\subsection{Data Preprocessing: Augumentation and Cleaning}
As part of the preprocessing pipeline, non-square images were removed from the dataset prior to 
training. This decision was made to avoid potential issues associated with direct resizing or 
aspect-ratio-preserving padding, both of which can negatively impact the performance of CNN. To 
ensure consistency and compatibility with the input requirements of CNN, all remaining images were 
resized to a uniform resolution of 224×224 pixels. 

Although techniques such as padding can preserve the original aspect ratio, they introduce 
artificial borders and non-informative regions into the image. These artifacts may be misinterpreted 
by the CNN as meaningful features, especially in the early convolutional layers, which are  
sensitive to spatial patterns. As a result, the model might learn irrelevant cues and generalize  
poorly, particularly in medical imaging tasks where precision is critical.

Furthermore, direct resizing of non-square images to a fixed square input size results in geometric 
distortion, altering the shape, size, and orientation of key anatomical structures such as lung 
nodules. This deformation can obscure clinically relevant patterns and lead to degraded model 
performance, especially in tasks involving subtle morphological differences between classes.

\vspace{1em}
\begin{center} 
    \includegraphics
    [width=0.7\textwidth]{../assets/02-dataset/label-distribution-after-preprocessing.png}

    \small\textit{\hypertarget{figura3}Figure 3. Distribution of images label after preprocessing.}
\end{center}
\vspace{1em}

The original dataset exhibited a significant imbalance among the diagnostic categories, which could 
adversely affect model training and lead to biased predictions. Specifically, the initial dataset 
included: 40 malignant cases, 15 benign cases and 55 normal (non-nodule) cases. To address this 
issue and ensure a more balanced distribution of classes, extensive data augmentation techniques to 
artificially expand the dataset were applied. The goal was to create a more uniform class 
distribution and enhance the model’s ability to generalize across all categories. The augmentation 
techniques applied include: Horizontal Flip, Vertical Flip, Rotation, Colorjitter, Contour Crop, 
Gaussian Blur, Sharpeness, Contrast and Histogram Equalization \cite{subhajeet_das_2025}.

\vspace{1em}
\begin{center} 
    \includegraphics[width=\textwidth]{../assets/02-dataset/label-distribution.png}

    \small\textit{\hypertarget{figura3}Figure 3. Distribution of images label compared to the 
    original dataset.}
\end{center}
\vspace{1em}

\subsection{Data Splitting: Training, Test and Validation}
To ensure effective training, evaluation, and generalization of the Convolutional Neural Network 
(CNN), the dataset was split into three subsets using the following proportions: 75\% Training Set, 
15\% Validation Set and 15\% Test Set.

\begin{itemize}
    \item \textbf{Effective Learning:} Allocating the majority of the data to the training set 
    ensures that the model has sufficient samples to learn patterns, especially in a medical imaging 
    context where inter-class variations may be subtle and complex.

    \item \textbf{Hyperparameter Tuning:} The validation set is used to monitor the model’s 
    performance during training and to fine-tune hyperparameters. This helps prevent overfitting by 
    evaluating how well the model generalizes to unseen data during the training process.

    \item \textbf{Unbiased Performance Evaluation:} The test set is strictly separated from the 
    training and validation processes. It provides an objective estimate of the model’s real-world 
    performance, helping ensure that performance metrics are not inflated by exposure to the 
    training data.
\end{itemize}

This division plays a crucial role in the training workflow and contributes to the development of a 
robust and unbiased model.
\subsection{Challenges and Limitations}

